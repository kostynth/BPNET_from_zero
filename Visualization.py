import matplotlib.pyplot as plt
import numpy as np

BP_classic_loss = [

1.4499215261441762
,1.4114441223037018,
1.227647949177019
,0.16162728202911017
,0.11019370570043648
,0.0811714760996649
,0.07577116265728524
,0.07482027849535737
,0.07308405388317729
,0.07007479763047539
,0.06855364389272353
,0.06825855835314347
,0.06801746945273751
,0.06780377324467723
,0.06762245440054611
,0.06747247389104691
,0.0673505355036334
,0.06725264589329384
,
0.06717478059117422
,0.06711323539812793
,
0.06706479336868822
,
0.06702676977056887
,
0.06699698371218192
,
0.06697369424003663
,
0.066955525959093
,
0.06694139800876461
,
0.066930462448517
,
0.0669220536009512
,
0.0669156476937323
,
0.06691083128961696
,
0.06690727683667383
,
0.06690472381952137
,
0.06690296424310874
,
0.06690183143786402
,
0.0669011914009776
,
0.06690093607297666
,
0.06690097809338362
,
0.06690124669019153
,0.06690168444192283
,0.06690224471427823
,0.0669028896208578
,0.06690358839307839
,0.06690431607122097
,
0.06690505244876897
,
0.06690578121751903
,
0.06690648927259997
,
0.06690716614544433
,
0.06690780353959772
,
0.06690839494953327
,
0.06690893534673398
,
0.06690942092049966
,
0.06690984886343647
,
0.06691021719355497
,
0.06691052460645987
,
0.06691077035234921
,
0.06691095413352749
,
0.06691107601892556
,
0.06691113637275552
,
0.06691113579494021
,
0.06691107507137242
,
0.06691095513239574
,
0.06691077701817458
,
0.06691054184984532
,
0.06691025080552644
,
0.06690990510041632
,
0.06690950597033428
,
0.06690905465816398
,
0.06690855240274432
,
0.06690800042982585
,
0.06690739994476959
,
0.06690675212671612
,
0.06690605812399471
,
0.06690531905057716
,
0.06690453598341123
,
0.06690370996049327
,
0.0669028419795612
,
0.06690193299730611
,
0.06690098392901725
,

0.06689999564858637
,

0.06689896898881
,
0.06689790474193606
,0.06689680366041041
,0.06689566645778484
,0.06689449380975407
,0.06689328635529433
,0.06689204469788027
,0.0668907694067603
,0.06688946101827419
, 0.06688812003719866
,0.06688674693810902
, 0.06688534216674799
,0.06688390614139256
,0.06688243925421304
,0.06688094187261827
, 0.06687941434058293
,0.06687785697995322
,0.06687627009172809
,0.06687465395731415
,0.06687300883975217
,0.06687133498491434
]
BP_swarm_opt_loss =[0.4722186446440827
, 0.07903831839051284
, 0.07637803421514819
,0.07512533332936096
,0.07491246989037476
,0.07489434544001596
, 0.07469817039964873
,0.07433683518631817
,0.07078423776498191
, 0.06997054862044755
, 0.06559278356991925
, 0.06555283990379347
, 0.05583892393374067
, 0.05537244882681262
, 0.05471449896674071
, 0.0528977387387604
, 0.05245962139120214
, 0.05136922336712236
,0.05119948933769468
, 0.05083898124143196
, 0.050176118758684995
, 0.050049920460305666
, 0.05004263973875064
, 0.049956277989605176
, 0.04972009925708349
, 0.049705715106306766
, 0.049661460093706374
, 0.04920550313925742
, 0.04844602877590692
, 0.04736170523583172
, 0.04734498136896486
, 0.04711784455366455
, 0.046160454107662535
, 0.04600540680574678
, 0.04542446840955808
, 0.04266433430051209
,0.042357886075756815
,0.042311152956748865
,0.0410885741117333
,0.04023052334401724
, 0.03938496483465484
, 0.036689037503366
,0.035767979226360054
,0.028978972799577847
,0.02867893281493009
, 0.028195693861148962
,0.027990280589407005
, 0.027827588037409187
,0.027795289025849292
, 0.027683846552149217
, 0.027652919479181762
,0.02746441752165051
, 0.026929637468107177
, 0.02586174559384499
, 0.025599781073373535
, 0.025005634496606765
,0.024915371720298354
,0.02458888941395199
,0.024435267020482057
, 0.024435267020482057
, 0.024434500876198667
,0.024379872954633654
,0.024352474135267824
, 0.02405817177529357
, 0.022747817416111798
,0.02258629181828621
,
0.022429492749392564
,0.022284820345747473
,0.022013687661089812
,0.02188350496646885
,0.02143189396918267
,0.019194237619879574
,0.01913930697410419
,0.018709264706537033
, 0.017713764775557087
, 0.017586431230587493
,0.01752401264897169
, 0.017448263346435747
,0.016978296352707777
, 0.016808655723125315
,0.016779973797196028
, 0.01660209528868517
, 0.0165536054286525
,0.0163231681482732
, 0.0163231681482732
,0.016201292582272018
, 0.016100321615456853
, 0.01602752494347312
,0.01598436131234167
,0.01598436131234167
,0.015924025502139023
, 0.01566431872693317
, 0.015424009548931495
,0.01526363963731091
, 0.01513783372713377
,0.014737031260489811
,0.014737031260489811
,0.014240144213968626
,0.014237991521767752
,0.01364049752234808]



epochs = np.linspace(0, 10000, 100)
fig, ax = plt.subplots()

(line1, ) = ax.plot(epochs, np.log(np.array(BP_classic_loss)), lw=2, label='BP_classic_loss')
(line2, ) = ax.plot(epochs, np.log(np.array(BP_swarm_opt_loss)), lw=2, label='BP_swarm_opt_loss')

leg = ax.legend(fancybox=True, shadow=True)

lines = [line1, line2]
map_legend_to_ax = {}
line1.axes.get_yaxis().set_visible(False)
pickradius = 5


leg.set_draggable(True)

plt.show()
